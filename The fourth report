%-- coding: UTF-8 --
\documentclass[12pt, letterpaper, twoside]{article}
\usepackage[UTF8]{ctex}
\usepackage{graphicx} % Required for inserting images
\usepackage{geometry} % 页面布局
\usepackage{graphicx} % 图片插入
\usepackage{hyperref} % 超链接
\usepackage{listings} % 代码段
\usepackage{fancyhdr} % 页眉页脚
\usepackage{titlesec} % 章节标题格式
\usepackage{xcolor} % 颜色
\usepackage{tocloft} % 目录设置
\usepackage{indentfirst} % 首段缩进
\usepackage{array}
\lstset{
     columns = fixed,       
     basicstyle = \linespread{0.8} \ttfamily,             % 设置行距，字体
     numberstyle = \tiny \color{gray},                    % 设定行号格式
     keywordstyle = \bfseries \color[RGB]{40,40,255},     % 设定关键字颜色
     numberstyle = \footnotesize \color{darkgray},           
     commentstyle = \color[RGB]{0,96,96},                 % 设置代码注释的格式
     stringstyle = \color[RGB]{128,0,0},                  % 设置字符串格式
     frame = single,                                      % 不显示背景边框
     backgroundcolor = \color[RGB]{245,245,244},          % 设定背景颜色
     showstringspaces = false,                            % 不显示字符串中的空格
     language=Python                                          % 设置语言
}


\title{第四次实验报告}
\author{谢宇倩 21070001106}
\date{September 2024}

\begin{document}

\maketitle
\newpage

\section{调试及性能分析}

\subsection{调试}
\begin{itemize}

\item 使用 Linux 上的 journalctl 或 macOS 上的 log show 命令来获取最近一天中超级用户的登录信息及其所执行的指令。\\
在终端输入命令：\\
\begin{lstlisting}
~$ journalctl | grep sudo
\end{lstlisting}
返回了超级用户的登录信息及其所执行的指令。\\
\includegraphics [width=0.9\textwidth]{images/1.png} \\
sudo ls后再次使用journalctl命令，可以看到最后添上了执行ls的详细信息。\\
\includegraphics [width=0.9\textwidth]{images/2.png} \\
\item 学习pdb实践教程并熟悉相关的命令。\\
对参考链接所给的pdb实践教程进行了学习和熟悉：\\
\includegraphics [width=0.9\textwidth]{images/3.png} \\
\item 安装 shellcheck 并尝试对下面的脚本进行检查。这段代码有什么问题吗？请修复相关问题。在您的编辑器中安装一个 linter 插件，这样它就可以自动地显示相关警告信息。
\newpage
\begin{lstlisting}
#!/bin/sh
## Example: a typical script with several problems
for f in $(ls *.m3u)
do
  grep -qi hq.*mp3 $f \
    && echo -e 'Playlist $f contains a HQ file in mp3 
    format'
done
\end{lstlisting}
首先，在\lstinline|~/.vimrc|中添加\lstinline|Plug 'neomake/neomake'| ，\\
\includegraphics [width=0.9\textwidth]{images/4.png} \\
然后在vim中执行\lstinline|PlugInstall|安装插件。\\
\includegraphics [width=0.9\textwidth]{images/5.png} \\
在所给脚本中执行\lstinline|:Neomake|进行shellcheck检查：\\
\includegraphics [width=0.9\textwidth]{images/6.png} \\
\textcolor{red}{警告和错误分析}：\\
a. \lstinline|for f in $(ls *.m3u) |使用命令替换来获得\lstinline|ls *.m3u |的输出。虽然在某些情况下可能起作用，但如果文件名包含空格或特殊字符就可能会导致问题。更好的做法是使用通配符模
式：\lstinline|for f in *.m3u| 。\\
b. echo 语句中变量\lstinline|$f|没有用引号括起来，这样如果文件名包含空格的话，它们将被视为不
同的参数。为了正确处理文件名，这行应修改为：\lstinline|echo -e "Playlist '$f'|。\\
c. 用\lstinline|grep|进行字符串匹配时候的 -i 选项用于执行不区分大小写的搜索，\lstinline| hq.*mp3|匹配以 "hq" 开头并以 "mp3" 结尾的字符串，可能会匹配到不表示实际MP3文件
的文件名。可以改为\lstinline|hq.*\.mp3$|。\\
\end{itemize}

\subsection{性能分析}
\begin{itemize}
\item 这里有一些排序算法的实现。请使用 cProfile 和 line\_profiler 来比较插入排序和快速排序的性能。两种算法的瓶颈分别在哪里？然后使用 memory\_profiler 来检查内存消耗，为什么插入排序更好一些？然后再看看原地排序版本的快排。附加题：使用 perf 来查看不同算法的循环次数及缓存命中及丢失情况。\\
使用 cProfile 工具，按照执行时间排序并使用文本搜索过滤输出，只显示sorts.py文件中函数的性能数据：
\begin{lstlisting}
 python3 -m cProfile -s time sorts.py | grep sorts.py
\end{lstlisting}
\includegraphics [width=0.9\textwidth]{images/8.png} \\
以看出 quicksort 函数和 test\_sorted 函数的 cumtime 相对较高。\\
然后安装line\_profiler进行分析，给函数添加上装饰器@profile后：\\
\begin{lstlisting}
 kernprof -l -v sorts.py
\end{lstlisting}
插入排序：\\ \includegraphics [width=0.9\textwidth]{images/10.png} \\
插入排序的执行总时间：0.291017 秒，可以看出函数的性能瓶颈主要在第 16 行和第 17 行，它们的执行时间占总执行时间的很大一部分（66\%），尤其是第 16 行的 while 循环。\\
快速排序：\\ \includegraphics [width=0.9\textwidth]{images/9.png} \\
总时间0.122638 秒，性能瓶颈主要在第 27 行和第 28 行的列表推导式，它们占总执行时间的62.6\%，特别是创建了包含所有小于基准元素的列表的第 27 行。
然后使用 memory\_profiler，也是添上装饰器@profile。\\
\begin{lstlisting}
python3 -m memory_profiler sorts.py
\end{lstlisting}
插入排序：\\ \includegraphics [width=0.9\textwidth]{images/11.png} \\
从输出结果可以看出插入排序函数在执行过程中内存使用量相对稳定，没有显著的内存增量。
上学期我学了数据结构，知道插入排序是稳定的排序算法，它在原地进行排序，不需要额外的数组来存储排序过程中的数据，因此内存使用量相对较低。\\
快速排序：\\ \includegraphics [width=0.9\textwidth]{images/12.png} \\
快速排序算法是递归的，每次递归调用都会创建新的栈帧，\textcolor{red}{按理来说内存应该会有显著增量，但在输出结果中没有体现出来}，可能是因为测试的数据集太小了。\\
对比原地操作的快速排序算法内存情况：\\
\includegraphics [width=0.9\textwidth]{images/13.png} \\
从输出结果可以看出，原地操作的快速排序算法内存使用量保持相对稳定，没有显著的内存增量。它也是一个原地排序算法，在排序过程中不需要额外的数组来存储数据。\\
接着使用perf检查每个算法的循环次数、缓存命中和丢失。\\
\begin{lstlisting}
sudo perf stat -e cycles,cache-references,cache-misses 
python3 sorts.py
\end{lstlisting}
插入排序：\\ \includegraphics [width=0.9\textwidth]{images/14.png} \\
快速排序：\\ \includegraphics [width=0.9\textwidth]{images/15.png} \\
这里返回cycles、cache-references和cache-misses都返回<not supported>，我的计算机不支持这些性能计数器，不过可以看到time elapsed、user和sys的数据。\\
\item 这里有一些用于计算斐波那契数列 Python 代码，它为计算每个数字都定义了一个函数：
\newpage
\begin{lstlisting}
#!/usr/bin/env python
def fib0(): return 0

def fib1(): return 1

s = """def fib{}(): return fib{}() + fib{}()"""

if __name__ == '__main__':

    for n in range(2, 10):
        exec(s.format(n, n-1, n-2))
    # from functools import lru_cache
    # for n in range(10):
    #     exec("fib{} = lru_cache(1)(fib{})"
    .format(n, n))
    print(eval("fib9()"))
\end{lstlisting}
将代码拷贝到文件中使其变为一个可执行的程序。首先安装 pycallgraph 和 graphviz。并使用 pycallgraph graphviz -- ./fib.py 来执行代码并查看 pycallgraph.png 这个文件。fib0 被调用了多少次？我们可以通过记忆法来对其进行优化。将注释掉的部分放开，然后重新生成图片。这回每个 fibN 函数被调用了多少次？\\
首先安装工具：\\
\includegraphics [width=0.9\textwidth]{images/16.png} \\
然后使用 pycallgraph graphviz -- ./fib.py 来执行代码并查看pycallgraph.png。\\
\includegraphics [width=0.9\textwidth]{images/17.png} \\
\includegraphics [width=0.9\textwidth]{images/18.png} \\
可见fib0 被调用了\textcolor{red}{34}次。\\
将注释掉的部分放开，然后重新生成图片。\\
\includegraphics [width=0.9\textwidth]{images/19.png} \\
\begin{lstlisting}
34
fib2() 被调用了 34 次
fib3() 被调用了 21 次
fib4() 被调用了 13 次
fib5() 被调用了 8 次
fib6() 被调用了 5 次
fib7() 被调用了 3 次
fib8() 被调用了 2 次
fib9() 被调用了 1 次
\end{lstlisting}
\item 我们经常会遇到的情况是某个我们希望去监听的端口已经被其他进程占用了。让我们通过进程的 PID 查找相应的进程。首先执行 python -m http.server 4444 启动一个最简单的 web 服务器来监听 4444 端口。在另外一个终端中，执行 lsof | grep LISTEN 打印出所有监听端口的进程及相应的端口。找到对应的 PID 然后使用 kill <PID> 停止该进程。\\
\includegraphics [width=0.9\textwidth]{images/20.png} \\
在第二个终端中看到PID为7282，kill 7282后第一个终端中立马出现Terminated。\\
\item 限制进程资源也是一个非常有用的技术。执行 stress -c 3 并使用 htop 对 CPU 消耗进行可视化。现在，执行 taskset --cpu-list 0,2 stress -c 3 并可视化。stress 占用了 3 个 CPU 吗？为什么没有？阅读 man taskset 来寻找答案。附加题：使用 cgroups 来实现相同的操作，限制 stress -m 的内存使用。\\
先执行 stress -c 3 用 htop 对 CPU 消耗进行可视化。\\
\includegraphics [width=0.9\textwidth]{images/21.png} \\\includegraphics [width=0.9\textwidth]{images/22.png} \\
然后执行 taskset --cpu-list 0,2 stress -c 3 并可视化。\\
\includegraphics [width=0.9\textwidth]{images/23.png} \\\includegraphics [width=0.9\textwidth]{images/24.png} \\
\end{itemize}
\section{元编程}
\begin{itemize}
\item 大多数的 makefiles 都提供了 一个名为 clean 的构建目标，这并不是说我们会生成一个名为 clean 的文件，而是我们可以使用它清理文件，让 make 重新构建。您可以理解为它的作用是“撤销”所有构建步骤。在上面的 makefile 中为 paper.pdf 实现一个 clean 目标。您需要将构建目标设置为 phony。\\
使用rm命令实现clean目标：\\
\includegraphics [width=0.9\textwidth]{images/25.png} \\
实现！\\
\includegraphics [width=0.9\textwidth]{images/26.png} \\
\item 学习 Rust 的构建系统 的依赖管理。\\
对所给内容进行了阅读学习。\\
\includegraphics [width=0.9\textwidth]{images/27.png} \\
\item Git 可以作为一个简单的 CI 系统来使用，在任何 git 仓库中的 .git/hooks 目录中，您可以找到一些文件（当前处于未激活状态），它们的作用和脚本一样，当某些事件发生时便可以自动执行。请编写一个 pre-commit 钩子，它会在提交前执行 make paper.pdf 并在出现构建失败的情况拒绝您的提交。这样做可以避免产生包含不可构建版本的提交信息；\\
修改.git/hooks 目录下面的pre-commit.sample文件并将其命名为pre-commit。\\
\begin{lstlisting}
if  ! make ; then
     echo "build failed, commit rejected"
     exit 1
fi
\end{lstlisting}
实现了如果make失败就拒绝提交并返回错误信息。\\
\includegraphics [width=0.9\textwidth]{images/28.png} \\
检验钩子：有一个名为 Makefile 的构建文件，用于生成 paper.pdf ，在当前环境下git commit会失败。\\
\includegraphics [width=0.9\textwidth]{images/29.png} \\
\item 基于 GitHub Pages 创建任意一个可以自动发布的页面。添加一个 GitHub Action 到该仓库，对仓库中的所有 shell 文件执行 shellcheck(方法之一)；\\
我使用的是所给的示例仓库。\\
\includegraphics [width=0.9\textwidth]{images/30.png} \\ \includegraphics [width=0.9\textwidth]{images/31.png} \\
进入 action 页面修改blank.yml:\\
\includegraphics [width=0.9\textwidth]{images/32.png} \\
\includegraphics [width=0.9\textwidth]{images/33.png} \\
执行action后出现错误：\\
\includegraphics [width=0.9\textwidth]{images/34.png} \\
根据提示修改错误后成功。\\
\includegraphics [width=0.9\textwidth]{images/35.png} \\
\includegraphics [width=0.9\textwidth]{images/36.png} \\
\item 构建属于您的 GitHub action，对仓库中所有的 .md 文件执行 proselint 或 write-good，在您的仓库中开启这一功能，提交一个包含错误的文件看看该功能是否生效。\\
在 Github marketplace 中找到Lint Markdown。\\
\includegraphics [width=0.9\textwidth]{images/37.png} \\
修改blank.yml：\\
\includegraphics [width=0.9\textwidth]{images/38.png} \\
在仓库中开启这一功能。\\
\includegraphics [width=0.9\textwidth]{images/39.png} \\
提交了一个包含错误的文件，发现该功能生效。\\
\includegraphics [width=0.9\textwidth]{images/40.png} \\
\end{itemize}

\section{pytorch入门}
这一部分我对老师发在群里的参考资料进行了学习，做了每个单元的练习题，最后在云端复现所给代码，完成了模型的构建过程。\\
\begin{itemize}

\item 单元练习题\\
\includegraphics [width=0.9\textwidth]{images/41.png} \\
\includegraphics [width=0.9\textwidth]{images/42.png} \\
\includegraphics [width=0.9\textwidth]{images/43.png} \\
\includegraphics [width=0.9\textwidth]{images/44.png} \\
\includegraphics [width=0.9\textwidth]{images/45.png} \\

\item 模型构建\\
\includegraphics [width=0.9\textwidth]{images/46.png} \\
进行多轮训练：\\
\includegraphics [width=0.9\textwidth]{images/47.png} \\
训练完毕，\textcolor{red}{Predicted:"Ankle boot",Actual:"Ankle boot"}，成功！\\
\includegraphics [width=0.9\textwidth]{images/49.png} \\
完成教程。\\
\includegraphics [width=0.9\textwidth]{images/48.png} \\
\end{itemize}

\section{心得体会}

本周的实验对调试及性能分析、元编程进行了学习，并对Pytorch进行了入门。

调试和性能分析能够帮助我们理解代码的运行状态，发现并修复错误，优化性能，是软件开发中的重要技能。使用journalctl能进行实时日志查看，监控服务的启动、运行和错误信息，能极大提高问题定位的效率。对pdb的学习提升了我对代码执行流程的理解和对调试复中杂逻辑的错误的理解，让我深入到代码的每一行，观察变量的变化。shellcheck更是一个实用高效的工具，在实验中通过让它帮助我发现脚本中的语法错误等，我认识到了它的强大之处，我觉得它会是我以后科研或工作生涯中的一个得力助手。cProfile、in\_profiler、memor\_profiler这些工具通过量化地展示程序的性能或内存使用情况，清晰明了地向我展现了程序的瓶颈，能够利用它们输出的结果有针对性地对程序进行优化。pycallgraph更是一个特别牛的工具，它把Python 程序调用流程可视化了，生动地向我展示了递归函数的调用过程，让我不用再像学C语言的时候一样对着代码冥思苦想了……

元编程是指编写能够操作和生成程序代码的程序。通过本次实验，我了解了元编程的概念和原理，并学习了一些常见的元编程技术，例如宏、模板编程和注解处理器。它们可以帮助我在编写代码时自动生成重复的代码和在编译时进行代码检查和转换。我还学会了如何编写代码模板或规范，然后使用元编程技术将其自动生成为可执行的代码，以此提高代码的生产率和可维护性。

入门Pytorch算是我第一次接触机器学习，我理解了张量的概念，学会了怎样加载和规范化数据集、生成模型层、自动差异化，了解了优化循环和模型预测……我体会到了动态图的强大之处，认识到迭代在机器学习中的重要性。最后通过完整的模型构建过程，我体会到了机器学习训练成功后给人带来的满满成就感。

总而言之，本次实验让我接触到了更多实用且强大的工具，提升了我的问题解决能力，还让我入门了机器学习。

\textbf{ 最后还是一样附上 github ：https://github.com/xxxyuq/my\_first}

\end{document}
